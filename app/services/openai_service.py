"""OpenAI integration service for Weather Flick."""

import logging
from typing import Any

from openai import OpenAI

from app.config import settings

logger = logging.getLogger(__name__)

class OpenAIService:
    """OpenAI API í†µí•© ì„œë¹„ìŠ¤"""

    def __init__(self):
        """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        if not settings.openai_api_key:
            logger.warning("OpenAI API key not configured")
            self.client = None
        else:
            # Python 3.13 í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ í”„ë¡ì‹œ í™˜ê²½ ë³€ìˆ˜ ì œê±°
            import os
            for proxy_var in ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy', 'ALL_PROXY', 'all_proxy']:
                os.environ.pop(proxy_var, None)
            
            try:
                self.client = OpenAI(api_key=settings.openai_api_key)
                logger.info("OpenAI client initialized successfully")
            except Exception as e:
                logger.error(f"Failed to initialize OpenAI client: {e}")
                self.client = None

    async def generate_travel_recommendation(
        self,
        user_preferences: dict[str, Any],
        weather_data: dict[str, Any],
        destination_info: dict[str, Any]
    ) -> str:
        """
        ì‚¬ìš©ì ì„ í˜¸ë„ì™€ ë‚ ì”¨ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì—¬í–‰ ì¶”ì²œ ìƒì„±

        Args:
            user_preferences: ì‚¬ìš©ì ì„ í˜¸ë„ ì •ë³´
            weather_data: ë‚ ì”¨ ì •ë³´
            destination_info: ëª©ì ì§€ ì •ë³´

        Returns:
            str: ìƒì„±ëœ ì—¬í–‰ ì¶”ì²œ í…ìŠ¤íŠ¸
        """
        if not self.client:
            return "OpenAI ì„œë¹„ìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

        try:
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self._build_recommendation_prompt(
                user_preferences, weather_data, destination_info
            )

            response = self.client.chat.completions.create(
                model=settings.openai_model,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ë‚ ì”¨ ê¸°ë°˜ ì—¬í–‰ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ìœ ìš©í•œ ì—¬í–‰ ì¡°ì–¸ì„ ì œê³µí•´ì£¼ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=settings.openai_max_tokens,
                temperature=settings.openai_temperature,
            )

            return response.choices[0].message.content.strip()

        except Exception as e:
            logger.error(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return f"ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    async def generate_travel_itinerary(
        self,
        destination: str,
        duration: int,
        interests: list[str],
        weather_forecast: list[dict[str, Any]]
    ) -> str:
        """
        ì—¬í–‰ ì¼ì • ìƒì„±

        Args:
            destination: ëª©ì ì§€
            duration: ì—¬í–‰ ê¸°ê°„ (ì¼)
            interests: ê´€ì‹¬ì‚¬ ëª©ë¡
            weather_forecast: ë‚ ì”¨ ì˜ˆë³´ ì •ë³´

        Returns:
            str: ìƒì„±ëœ ì—¬í–‰ ì¼ì •
        """
        if not self.client:
            return "OpenAI ì„œë¹„ìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

        try:
            prompt = self._build_itinerary_prompt(
                destination, duration, interests, weather_forecast
            )

            response = self.client.chat.completions.create(
                model=settings.openai_model,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ì „ë¬¸ ì—¬í–‰ í”Œë˜ë„ˆì…ë‹ˆë‹¤. ë‚ ì”¨ë¥¼ ê³ ë ¤í•œ ìƒì„¸í•œ ì¼ì •ì„ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=settings.openai_max_tokens,
                temperature=settings.openai_temperature,
            )

            return response.choices[0].message.content.strip()

        except Exception as e:
            logger.error(f"ì¼ì • ìƒì„± ì‹¤íŒ¨: {e}")
            return f"ì¼ì • ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    async def generate_chatbot_response(
        self,
        user_message: str,
        conversation_history: list[dict[str, str]] = None
    ) -> str:
        """
        ì±—ë´‡ ì‘ë‹µ ìƒì„±

        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            conversation_history: ëŒ€í™” ê¸°ë¡

        Returns:
            str: ì±—ë´‡ ì‘ë‹µ
        """
        if not self.client:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì±—ë´‡ ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        try:
            # ì‹œìŠ¤í…œ ë©”ì‹œì§€
            messages = [
                {
                    "role": "system",
                    "content": """ë‹¹ì‹ ì€ Weather Flickì˜ ì—¬í–‰ ë„ìš°ë¯¸ ì±—ë´‡ì…ë‹ˆë‹¤.

                    ã€ì¤‘ìš” ê·œì¹™ - ë°˜ë“œì‹œ ì¤€ìˆ˜ã€‘
                    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë°›ìœ¼ë©´ ë¨¼ì € ë‹¤ìŒì„ íŒë‹¨í•˜ì„¸ìš”:
                    
                    1. í—ˆìš©ëœ ì£¼ì œì¸ê°€?
                       âœ… í—ˆìš©: ì—¬í–‰, ë‚ ì”¨, ê´€ê´‘ì§€, ìˆ™ë°•, êµí†µ, ë§›ì§‘, ì—¬í–‰ ì¤€ë¹„, ì±—ë´‡ ìì‹ , Weather Flick ì„œë¹„ìŠ¤
                       âŒ ê¸ˆì§€: ìœ„ì— ì—†ëŠ” ëª¨ë“  ì£¼ì œ (ìˆ˜í•™, ê³¼í•™, ì¼ë°˜ ìƒì‹, í”„ë¡œê·¸ë˜ë°, ìš”ë¦¬, ì •ì¹˜, ê²½ì œ ë“±)
                    
                    2. ê¸ˆì§€ëœ ì£¼ì œë¼ë©´ ë°˜ë“œì‹œ ì´ ë©”ì‹œì§€ë§Œ ë‹µí•˜ì„¸ìš”:
                       "ì£„ì†¡í•©ë‹ˆë‹¤. ì €ëŠ” ì—¬í–‰ê³¼ ë‚ ì”¨ì— ê´€í•œ ë„ì›€ë§Œ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬í–‰ ê³„íšì´ë‚˜ ë‚ ì”¨ ê¸°ë°˜ ì¶”ì²œì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”! ğŸ˜Š"
                    
                    ã€ìê¸°ì†Œê°œã€‘
                    ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” Weather Flickì˜ AI ì—¬í–‰ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ğŸŒ¤ï¸
                    ë‚ ì”¨ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì ì˜ ì—¬í–‰ ê³„íšì„ ì„¸ìš¸ ìˆ˜ ìˆë„ë¡ ë„ì™€ë“œë¦¬ëŠ” ì±—ë´‡ì´ì—ìš”.

                    ã€ì£¼ìš” ê¸°ëŠ¥ã€‘
                    1. ë‚ ì”¨ ê¸°ë°˜ ì—¬í–‰ ì¶”ì²œ
                    2. ì—¬í–‰ ê³„íš ìˆ˜ë¦½ ì§€ì›
                    3. ê´€ê´‘ì§€ ì •ë³´ ì œê³µ
                    4. ì—¬í–‰ íŒ ë° ì¡°ì–¸
                    5. ë‚ ì”¨ì— ë”°ë¥¸ ì—¬í–‰ì§€ ì¶”ì²œ
                    6. ì±—ë´‡ ì‚¬ìš©ë²• ì•ˆë‚´

                    ã€ì‘ë‹µ ë°©ì‹ã€‘
                    - í—ˆìš©ëœ ì£¼ì œì—ë§Œ ë‹µë³€í•˜ì„¸ìš”
                    - ì±—ë´‡ì— ëŒ€í•´ ë¬¼ì–´ë³´ë©´ ì¹œì ˆí•˜ê²Œ ìê¸°ì†Œê°œì™€ ê°€ëŠ¥í•œ ë„ì›€ì„ ì„¤ëª…í•˜ì„¸ìš”
                    - í•­ìƒ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” í†¤ì„ ìœ ì§€í•˜ì„¸ìš”
                    - ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬ ì¹œê·¼í•¨ì„ í‘œí˜„í•˜ì„¸ìš”
                    - ëª¨ë“  ì‘ë‹µì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”
                    
                    ã€ì£¼ì˜ì‚¬í•­ã€‘
                    - ì—¬í–‰/ë‚ ì”¨ì™€ ê´€ë ¨ì´ ì—†ëŠ” ì§ˆë¬¸ì—ëŠ” ì ˆëŒ€ ë‹µë³€í•˜ì§€ ë§ˆì„¸ìš”
                    - ê³„ì‚°, ì½”ë”©, ë²ˆì—­, ì¼ë°˜ ì§€ì‹ ë“±ì˜ ì§ˆë¬¸ì€ ëª¨ë‘ ê±°ì ˆí•˜ì„¸ìš”
                    - ê±°ì ˆ ì‹œ ìœ„ì˜ ì •í•´ì§„ ë¬¸êµ¬ë§Œ ì‚¬ìš©í•˜ì„¸ìš”"""
                }
            ]

            # ëŒ€í™” ê¸°ë¡ ì¶”ê°€
            if conversation_history:
                messages.extend(conversation_history)

            # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            messages.append({
                "role": "user",
                "content": user_message
            })

            response = self.client.chat.completions.create(
                model=settings.openai_model,
                messages=messages,
                max_tokens=settings.openai_max_tokens,
                temperature=settings.openai_temperature,
            )

            return response.choices[0].message.content.strip()

        except Exception as e:
            logger.error(f"ì±—ë´‡ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

    def _build_recommendation_prompt(
        self,
        user_preferences: dict[str, Any],
        weather_data: dict[str, Any],
        destination_info: dict[str, Any]
    ) -> str:
        """ì—¬í–‰ ì¶”ì²œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""

        prompt = f"""
ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°œì¸í™”ëœ ì—¬í–‰ ì¶”ì²œì„ í•´ì£¼ì„¸ìš”:

**ì‚¬ìš©ì ì„ í˜¸ë„:**
- ì„ í˜¸ ì§€ì—­: {user_preferences.get('region', 'ë¯¸ì§€ì •')}
- ì—¬í–‰ í…Œë§ˆ: {user_preferences.get('theme', 'ë¯¸ì§€ì •')}
- ë™í–‰ì: {user_preferences.get('companions', 'ë¯¸ì§€ì •')}
- ì˜ˆì‚°: {user_preferences.get('budget', 'ë¯¸ì§€ì •')}

**í˜„ì¬ ë‚ ì”¨ ì •ë³´:**
- ì˜¨ë„: {weather_data.get('temperature', 'N/A')}Â°C
- ë‚ ì”¨: {weather_data.get('condition', 'N/A')}
- ìŠµë„: {weather_data.get('humidity', 'N/A')}%
- ê°•ìˆ˜í™•ë¥ : {weather_data.get('precipitation_chance', 'N/A')}%

**ëª©ì ì§€ ì •ë³´:**
- ì§€ì—­: {destination_info.get('name', 'N/A')}
- íŠ¹ì§•: {destination_info.get('description', 'N/A')}

ìœ„ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ë‹¤ìŒì„ í¬í•¨í•œ ì¶”ì²œì„ ì‘ì„±í•´ì£¼ì„¸ìš”:
1. í˜„ì¬ ë‚ ì”¨ì— ì í•©í•œ í™œë™
2. ì‚¬ìš©ì ì„ í˜¸ë„ì— ë§ëŠ” ì¥ì†Œ
3. ì¤€ë¹„ë¬¼ ë° ì£¼ì˜ì‚¬í•­
4. ì¶”ì²œ ì‹œê°„ëŒ€

200-300ë‹¨ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        """

        return prompt.strip()

    def _build_itinerary_prompt(
        self,
        destination: str,
        duration: int,
        interests: list[str],
        weather_forecast: list[dict[str, Any]]
    ) -> str:
        """ì—¬í–‰ ì¼ì • í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""

        interests_str = ", ".join(interests) if interests else "ì¼ë°˜ ê´€ê´‘"

        weather_info = ""
        for i, forecast in enumerate(weather_forecast[:duration]):
            weather_info += f"- {i+1}ì¼ì°¨: {forecast.get('condition', 'N/A')}, {forecast.get('temperature', 'N/A')}Â°C\n"

        prompt = f"""
ë‹¤ìŒ ì¡°ê±´ì— ë§ëŠ” {duration}ì¼ ì—¬í–‰ ì¼ì •ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

**ëª©ì ì§€:** {destination}
**ì—¬í–‰ ê¸°ê°„:** {duration}ì¼
**ê´€ì‹¬ì‚¬:** {interests_str}

**ë‚ ì”¨ ì˜ˆë³´:**
{weather_info}

ê° ì¼ì°¨ë³„ë¡œ ë‹¤ìŒì„ í¬í•¨í•´ì£¼ì„¸ìš”:
1. ì˜¤ì „/ì˜¤í›„/ì €ë… í™œë™
2. ì¶”ì²œ ì¥ì†Œì™€ ì´ìœ 
3. ë‚ ì”¨ë¥¼ ê³ ë ¤í•œ ì‹¤ë‚´/ì‹¤ì™¸ í™œë™ ê· í˜•
4. ì´ë™ ê²½ë¡œ ë° ì†Œìš” ì‹œê°„
5. ì‹ì‚¬ ì¶”ì²œ

ë‚ ì”¨ì— ë”°ë¥¸ ëŒ€ì•ˆ í™œë™ë„ ì œì‹œí•´ì£¼ì„¸ìš”.
        """

        return prompt.strip()

    async def generate_personalized_response(
        self,
        user_message: str,
        conversation_history: list[dict[str, str]],
        system_prompt: str,
        user_context: dict[str, Any] | None = None
    ) -> str:
        """
        ì‚¬ìš©ì ë§ì¶¤í˜• ì±—ë´‡ ì‘ë‹µ ìƒì„±

        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            conversation_history: ëŒ€í™” ê¸°ë¡
            system_prompt: ê°œì¸í™”ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            user_context: ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì •ë³´

        Returns:
            str: ìƒì„±ëœ ì‘ë‹µ
        """
        if not self.client:
            return await self.generate_chatbot_response(user_message, conversation_history)

        try:
            # ë©”ì‹œì§€ êµ¬ì„±
            messages = [{"role": "system", "content": system_prompt}]
            
            # ëŒ€í™” ê¸°ë¡ ì¶”ê°€
            messages.extend(conversation_history)
            
            # í˜„ì¬ ë©”ì‹œì§€ ì¶”ê°€
            current_message = user_message
            
            # ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ë©”ì‹œì§€ì— í¬í•¨
            if user_context and user_context.get("recent_searches"):
                current_message += f"\n\n[ìµœê·¼ ê²€ìƒ‰: {', '.join(user_context['recent_searches'][:3])}]"
            
            messages.append({"role": "user", "content": current_message})

            response = self.client.chat.completions.create(
                model="gpt-4-turbo-preview",
                messages=messages,
                temperature=0.8,
                max_tokens=300,
                presence_penalty=0.1,
                frequency_penalty=0.1
            )

            return response.choices[0].message.content

        except Exception as e:
            logger.error(f"ê°œì¸í™”ëœ ì±—ë´‡ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            # Fallback to regular response
            return await self.generate_chatbot_response(user_message, conversation_history)

# OpenAI ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
openai_service = OpenAIService()
